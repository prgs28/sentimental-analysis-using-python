{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "cols = ['sentiment','id','date','query_string','user','text']\n",
    "df = pd.read_csv(\"tweetproc.csv\",header=None, names=cols, encoding='latin-1')\n",
    "df.drop(['id','date','query_string','user'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pre_clean_len'] = [len(t) for t in df.text]\n",
    "from pprint import pprint\n",
    "data_dict = {\n",
    "    'sentiment':{\n",
    "        'type':df.sentiment.dtype,\n",
    "        'description':'sentiment class - 0:negative, 1:positive'\n",
    "    },\n",
    "    'text':{\n",
    "        'type':df.text.dtype,\n",
    "        'description':'tweet text'\n",
    "    },\n",
    "    'pre_clean_len':{\n",
    "        'type':df.pre_clean_len.dtype,\n",
    "        'description':'Length of the tweet before cleaning'\n",
    "    },\n",
    "    'dataset_shape':df.shape\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleaning process: \n",
    "### 1.using beautiful soup to clean the data i.e. to remove html encoded data\n",
    "### 2.using re to clear person-tags and urls\n",
    "### 3.removing text encoding\n",
    "### 4.removing #tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tok = WordPunctTokenizer()\n",
    "urlcheck = r'https?://[A-Za-z0-9./]+'\n",
    "cleaner = r'@[A-Za-z0-9]+'\n",
    "combined_pat = r'|'.join((cleaner, urlcheck))\n",
    "def tweet_cleaner(text):\n",
    "    implement_soup = BeautifulSoup(text, 'lxml')\n",
    "    done = implement_soup.get_text()\n",
    "    data_stripped = re.sub(combined_pat, '', done)\n",
    "    try:\n",
    "        clean = data_stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        clean = data_stripped\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean)\n",
    "    lower_case = letters_only.lower()\n",
    "    words = tok.tokenize(lower_case)\n",
    "    return (\" \".join(words)).strip()\n",
    "testing = df.text[:100]\n",
    "test_result = []\n",
    "for t in testing:\n",
    "    test_result.append(tweet_cleaner(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the above function is used to clean all the data and then we append it to the dataframe\n",
    "## the below code will take a lot of time to execute because of the file size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this might take sometime.... wait!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(\"this might take sometime.... wait!\")\n",
    "ranger = [0,400000,800000,1200000,1600000]\n",
    "clean_tweet_texts = []\n",
    "for i in range(ranger[0],ranger[1]):                                                                   \n",
    "    clean_tweet_texts.append(tweet_cleaner(df['text'][i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.DataFrame(clean_tweet_texts,columns=['text'])\n",
    "clean_df['target'] = df.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv('tweet2.csv',encoding='utf-8')\n",
    "csv = 'tweet2.csv'\n",
    "my_df = pd.read_csv(csv,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    400000\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we will use the cleaned dataset for further processing.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import findspark\n",
    "#findspark.init()\n",
    "import pyspark as ps\n",
    "import warnings\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Context Created!!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # create SparkContext on all CPUs available: in my case I have 4 CPUs on my laptop\n",
    "    sc = ps.SparkContext('local[4]')\n",
    "    sqlContext = SQLContext(sc)\n",
    "    print(\"Spark Context Created!!\")\n",
    "except ValueError:\n",
    "    warnings.warn(\"Refering existing spark context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('tweet2.csv')\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399266"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "#this drops all the useless(NA) containing data\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_set, val_set, test_set) = df.randomSplit([0.98, 0.01, 0.01], seed = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import HashingTF\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.ml.feature import Tokenizer \n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+------+--------------------+--------------------+--------------------+-----+\n",
      "|_c0|                text|target|               words|                  tf|            features|label|\n",
      "+---+--------------------+------+--------------------+--------------------+--------------------+-----+\n",
      "|  0|awww that s a bum...|     0|[awww, that, s, a...|(65536,[8436,8847...|(65536,[8436,8847...|  0.0|\n",
      "|  1|is upset that he ...|     0|[is, upset, that,...|(65536,[1444,2071...|(65536,[1444,2071...|  0.0|\n",
      "|  2|i dived many time...|     0|[i, dived, many, ...|(65536,[2548,2888...|(65536,[2548,2888...|  0.0|\n",
      "|  3|my whole body fee...|     0|[my, whole, body,...|(65536,[158,11650...|(65536,[158,11650...|  0.0|\n",
      "|  4|no it s not behav...|     0|[no, it, s, not, ...|(65536,[1968,4488...|(65536,[1968,4488...|  0.0|\n",
      "|  5|  not the whole crew|     0|[not, the, whole,...|(65536,[8026,3398...|(65536,[8026,3398...|  0.0|\n",
      "|  6|          need a hug|     0|      [need, a, hug]|(65536,[17625,308...|(65536,[17625,308...|  0.0|\n",
      "|  7|hey long time no ...|     0|[hey, long, time,...|(65536,[594,2317,...|(65536,[594,2317,...|  0.0|\n",
      "|  8|k nope they didn ...|     0|[k, nope, they, d...|(65536,[20464,206...|(65536,[20464,206...|  0.0|\n",
      "|  9|        que me muera|     0|    [que, me, muera]|(65536,[24439,246...|(65536,[24439,246...|  0.0|\n",
      "| 10|spring break in p...|     0|[spring, break, i...|(65536,[20639,207...|(65536,[20639,207...|  0.0|\n",
      "| 11|i just re pierced...|     0|[i, just, re, pie...|(65536,[2469,2441...|(65536,[2469,2441...|  0.0|\n",
      "| 12|i couldn t bear t...|     0|[i, couldn, t, be...|(65536,[8436,8997...|(65536,[8436,8997...|  0.0|\n",
      "| 13|it it counts idk ...|     0|[it, it, counts, ...|(65536,[6258,6589...|(65536,[6258,6589...|  0.0|\n",
      "| 14|i would ve been t...|     0|[i, would, ve, be...|(65536,[14,731,24...|(65536,[14,731,24...|  0.0|\n",
      "| 15|i wish i got to w...|     0|[i, wish, i, got,...|(65536,[8436,2063...|(65536,[8436,2063...|  0.0|\n",
      "| 16|hollis death scen...|     0|[hollis, death, s...|(65536,[5595,8026...|(65536,[5595,8026...|  0.0|\n",
      "| 17| about to file taxes|     0|[about, to, file,...|(65536,[8436,9324...|(65536,[8436,9324...|  0.0|\n",
      "| 18|ahh ive always wa...|     0|[ahh, ive, always...|(65536,[8436,1938...|(65536,[8436,1938...|  0.0|\n",
      "| 19|oh dear were you ...|     0|[oh, dear, were, ...|(65536,[2830,9318...|(65536,[2830,9318...|  0.0|\n",
      "+---+--------------------+------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashtf = HashingTF(numFeatures=2**16, inputCol=\"words\", outputCol='tf')\n",
    "idf = IDF(inputCol='tf', outputCol=\"features\", minDocFreq=5) \n",
    "label_stringIdx = StringIndexer(inputCol = \"target\", outputCol = \"label\")\n",
    "pipeline = Pipeline(stages=[tokenizer, hashtf, idf, label_stringIdx])\n",
    "Train_set_to_pipelineFit = pipeline.fit(train_set)\n",
    "train_df = Train_set_to_pipelineFit.transform(train_set)\n",
    "val_df = Train_set_to_pipelineFit.transform(val_set)\n",
    "train_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(maxIter=100)\n",
    "lrModel = lr.fit(train_df)\n",
    "predictions = lrModel.transform(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "e1 = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "e1.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = predictions.filter(predictions.label == predictions.prediction).count() / float(val_set.count())\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 1.0000\n",
      "ROC-AUC: 0.0000\n",
      "Wall time: 20.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "cv = CountVectorizer(vocabSize=2**16, inputCol=\"words\", outputCol='cv')\n",
    "idf = IDF(inputCol='cv', outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "label_stringIdx = StringIndexer(inputCol = \"target\", outputCol = \"label\")\n",
    "lr = LogisticRegression(maxIter=100)\n",
    "pipeline = Pipeline(stages=[tokenizer, cv, idf, label_stringIdx, lr])\n",
    "\n",
    "pipelineFit = pipeline.fit(train_set)\n",
    "predictions = pipelineFit.transform(val_set)\n",
    "accuracy = predictions.filter(predictions.label == predictions.prediction).count() / float(val_set.count())\n",
    "roc_auc = e1.evaluate(predictions)\n",
    "\n",
    "print (\"Accuracy Score: {0:.4f}\".format(accuracy))\n",
    "print (\"ROC-AUC: {0:.4f}\".format(roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import NGram, VectorAssembler\n",
    "from pyspark.ml.feature import ChiSqSelector\n",
    "\n",
    "def build_trigrams(inputCol=[\"text\",\"target\"], n=3):\n",
    "    tokenizer = [Tokenizer(inputCol=\"text\", outputCol=\"words\")]\n",
    "    ngrams = [\n",
    "        NGram(n=i, inputCol=\"words\", outputCol=\"{0}_grams\".format(i))\n",
    "        for i in range(1, n + 1)\n",
    "    ]\n",
    "\n",
    "    cv = [\n",
    "        CountVectorizer(vocabSize=2**14,inputCol=\"{0}_grams\".format(i),\n",
    "            outputCol=\"{0}_tf\".format(i))\n",
    "        for i in range(1, n + 1)\n",
    "    ]\n",
    "    idf = [IDF(inputCol=\"{0}_tf\".format(i), outputCol=\"{0}_tfidf\".format(i), minDocFreq=5) for i in range(1, n + 1)]\n",
    "\n",
    "    assembler = [VectorAssembler(\n",
    "        inputCols=[\"{0}_tfidf\".format(i) for i in range(1, n + 1)],\n",
    "        outputCol=\"rawFeatures\"\n",
    "    )]\n",
    "    label_stringIdx = [StringIndexer(inputCol = \"target\", outputCol = \"label\")]\n",
    "    selector = [ChiSqSelector(numTopFeatures=2**14,featuresCol='rawFeatures', outputCol=\"features\")]\n",
    "    lr = [LogisticRegression(maxIter=100)]\n",
    "    return Pipeline(stages=tokenizer + ngrams + cv + idf+ assembler + label_stringIdx+selector+lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trigram_train_set_pipelineFit = build_trigrams().fit(train_set)\n",
    "predictions = trigram_train_set_pipelineFit.transform(val_set)\n",
    "accuracy = predictions.filter(predictions.label == predictions.prediction).count() / float(train_set.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print accuracy, roc_auc\n",
    "print (\"Accuracy Score: {0:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.ml.feature import NGram, VectorAssembler\n",
    "\n",
    "def assemblyTweet(inputCol=[\"text\",\"target\"], n=3):\n",
    "    tokenizer = [Tokenizer(inputCol=\"text\", outputCol=\"words\")]\n",
    "    ngrams = [\n",
    "        NGram(n=i, inputCol=\"words\", outputCol=\"{0}_grams\".format(i))\n",
    "        for i in range(1, n + 1)\n",
    "    ]\n",
    "\n",
    "    cv = [\n",
    "        CountVectorizer(vocabSize=5460,inputCol=\"{0}_grams\".format(i),\n",
    "            outputCol=\"{0}_tf\".format(i))\n",
    "        for i in range(1, n + 1)\n",
    "    ]\n",
    "    idf = [IDF(inputCol=\"{0}_tf\".format(i), outputCol=\"{0}_tfidf\".format(i), minDocFreq=5) for i in range(1, n + 1)]\n",
    "\n",
    "    assembler = [VectorAssembler(\n",
    "        inputCols=[\"{0}_tfidf\".format(i) for i in range(1, n + 1)],\n",
    "        outputCol=\"features\"\n",
    "    )]\n",
    "    label_stringIdx = [StringIndexer(inputCol = \"target\", outputCol = \"label\")]\n",
    "    lr = [LogisticRegression(maxIter=100)]\n",
    "    return Pipeline(stages=tokenizer + ngrams + cv + idf+ assembler + label_stringIdx+lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "assembly_pipelineFit = assemblyTweet().fit(train_set)\n",
    "predictions_wocs = assembly_pipelineFit.transform(val_set)\n",
    "accuracy_wocs = predictions_wocs.filter(predictions_wocs.label == predictions_wocs.prediction).count() / float(val_set.count())\n",
    "roc_auc_wocs = e1.evaluate(predictions_wocs)\n",
    "\n",
    "# print accuracy, roc_auc\n",
    "print (\"Accuracy Score: {0:.4f}\".format(accuracy_wocs))\n",
    "print (\"ROC-AUC: {0:.4f}\".format(roc_auc_wocs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying transform on test_set\n",
    "\n",
    "test_predictions = assembly_pipelineFit.transform(test_set)\n",
    "#accuracy is calculated for test set\n",
    "test_accuracy = test_predictions.filter(test_predictions.label == test_predictions.prediction).count() / float(test_set.count())\n",
    "test_roc_auc = e1.evaluate(test_predictions)\n",
    "\n",
    "# print accuracy, roc_auc\n",
    "print (\"Accuracy Score: {0:.4f}\".format(test_accuracy))\n",
    "test1=test_accuracy*100\n",
    "print (\"Accuracy is: \", test1,\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
